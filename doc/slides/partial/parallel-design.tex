\section{Parallel Design}

\subsection{Data Structure}
\begin{frame}
    \frametitle{Online Data Structure}
    \begin{itemize}
    \setlength\itemsep{1em}
    	\item Incremental Suffix Maximum Query
    		\begin{itemize}
    			\setlength\itemsep{1em}
    			\item Binary Indexed Tree (Fenwick Tree): $\mathcal{O}(\log n)$
    			\item Segment Tree: $\mathcal{O}(\log n)$
    			\item Van Emde Boas Tree: $\mathcal{O}(\log \log n)$
    			\item Disjoint Set: $\Omega(\alpha(n))$
    			\item Sparse Table: $\mathcal{O}(n \log n)$ -- $\mathcal{O}(1)$
    		\end{itemize}
    	\item Which one is cache-friendly/ exploit parallelism easily?
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Offline RMQ Data Structure}
    \begin{itemize}
    \setlength\itemsep{1em}
    	\item Cache-oblivious cartesian tree
    	\footnote{Erik D. Demaine, On Cartesian Trees and Range Minimum Queries, MIT, 2009}
    	\item Parallel cartesian tree algorithm:  $\mathcal{O}(\frac{n}{p} \log^2 n + d)$, 
    		which $d$ is the maximum depth of the cartesian tree.
    	\footnote{Julian Shun, A Simple Parallel Cartesian Tree Algorithm and its Application 
    		to Parallel Suffix Tree Construction, Carnegie Mellon University, 2014}
    \end{itemize}
\end{frame}

\subsection{Parallel VGLCS}
\begin{frame}
	\frametitle{Data Dependency (TODO)}
	\begin{itemize}
		\setlength\itemsep{1em}
		\item We want to remove \texttt{All[i][j]} because its data dependency 
			is hard to parallel.
		\item The $O(n \log n)$ -- $O(1)$ sparse table is a good alternative plan. 
			However, parallel algorithm will be $O((n^2 \log n) / p + n \log n)$ with $p$ processors.
		\item Cache-oblivious sparse table run $O(n)$ -- $O(1)$ 
			with extra space $O(n)$ which record catalan number.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Data Layout (TODO)}
	\begin{itemize}
		\setlength\itemsep{1em}
		\item Dynamic data relocation improve the data locality
		\item Design auxiliary structure like fractional cascading
		\footnote{Churchill Navigation's Programming Challange 2015 \url{https://www.zhihu.com/question/27729745}}
		\item Use \textbf{van Emde Boas} layout whose leaves point to intervals in a packed memory structure.
		\footnote{MIT: Cache-Oblivious Search Trees Project \url{http://supertech.csail.mit.edu/cacheObliviousBTree.html}}
		\footnote{Gerth Stolting Brodal, Cache Oblivious Search Tree via Binary Trees of Small Height, 1999}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Serial VGLCS Algorithm (TODO)}
	If the length of two sequences are $n$, it runs in $\mathcal{O}(\mathcal{R} \; \alpha(n)))$ 
	from reference paper, which $\mathcal{R} = O(n^2)$. \\

	We have a better algorithm as follows:
	\begin{itemize}
		\setlength\itemsep{1em}
		\item Gernerate all structurally unique binary search tree, then compute the LCA of all pairs. 
			It uses $\theta(\sum_{i = 1}^{s} i^2 C_i)$ space.
			(Catalan number $C_n = \frac{1}{n+1} \binom{2n}{n} \sim \frac{4^n}{n^{1.5}}$)
		\item Use cache-oblivious sparse table, it runs in $\mathcal{\theta}(n^2)$.
			It is theoretically possible.
		\footnote{Johannes Fischer, V.H., A new succinct representation of 
				RMQ-information and improvements in the enhanced suffix array, 2007}
		\footnote{Masud Hasan, Cache oblivious algorithms for the RMQ and the RMSQ problems, 2010}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Parallel VGLCS Algorithm}
	How to parallel our better algorithm?
	\begin{itemize}
		\setlength\itemsep{1em}
		\item We need to pre-process all unique binary search trees with $[1, s]$ nodes,
			so the time complexity is at least $\theta(\sum_{i = 1}^{s} i^2 C_i) =  \theta(?)$.
		\item Finally, it runs in $O(?/p + \log \frac{n}{\log n}) = O(?/p + \log n)$ in parallel.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Parallel VGLCS Algorithm}
	Alternative plan for the above algorithm is using hybrid data structure.
	We can combine disjoint-set, sparse table, and cache-oblivious cartesian tree together.
	\begin{itemize}
		\setlength\itemsep{1em}
		%\item Disjoint-set: $\mathcal{O}(\frac{1}{p}(\mathcal{R} \; \alpha(n)))$.
		\item Sparse table with cartesian tree: $\mathcal{\theta}(\frac{n}{p} (n/s) \log (n/s))$.  
		We pick $s = \frac{\log n}{4}$, and time complexity is $\mathcal{\theta}(n/p + \log n)$ -- $\mathcal{O}(s)$.
		\item Most interval queries can be divided into two block queries
			and one superblock-query, and each query is $O(1)$. 
			Otherwise, inblock query is $O(s)$
	\end{itemize}
\end{frame}

\begin{frame}
    \begin{figure}[!thb]
      \centering
      \subfigure[]{
        \includegraphics[scale=0.5]{graphics/fig-interval-decomposition.pdf}
      }
      \subfigure[]{
        \includegraphics[scale=0.5]{graphics/fig-sparse-table.pdf}
      }
      \caption{Interval Decomposition}
      \label{fig:interval-decomposition}
    \end{figure}
\end{frame}

\begin{frame}
    \begin{center}
    \scalebox{0.6}{
    \begin{minipage}{1.5\linewidth}
      \begin{algorithm}[H]  
      	  \caption{Parallel Algorithm for Finding VGLCS}
  		  \label{alg:parallel}
          \begin{algorithmic}[1]
            \Require
              $A, B$: the input string;
              $G_A, G_B$: the array of variable gapped constraints;
            \Ensure Find the LCS with variable gapped constraints
            \State \tt{ISMQ} $Q[n]$
            \State \tt{int} $V[n][m]$
            \For{$i = 1$ to $n$}
              \State SparseTable $sp$
              \ParFor{$j = 1$ to $m$}
                \State $sp[j] = Q[j].get(r)$
              \EndParFor
              \State sp.parallel\_build(m) -- $O(n/p \log n + \log n)$
              \ParFor{$j = 1$ to $m$}
                \If{$A[i] = B[j]$}
                    \State $V[i][j] = sp.get(j - \min(GB[j]+1, j), j-1)+1$
                    \State $Q[j].set(i, V[i][j])$
                \EndIf
              \EndParFor
            \EndFor
            \State Retrieve the VGLCS by tracing $V[n][m]$
          \end{algorithmic}
      \end{algorithm}
    \end{minipage}%
    }
  \end{center}
\end{frame}

\begin{frame}
    \begin{center}
    \scalebox{0.6}{
    \begin{minipage}{1.5\linewidth}
      \begin{algorithm}[H]
      	\caption{Transfer Cartesian Tree to 64-bits with 8 integers}
  		\label{alg:cacheObliviousTransfer}
		\begin{algorithmic}[1]
		    \Require
		      $A[1 \cdots 16]$: 16 integers store in array
		    \Ensure 
		      $\textit{tmask}$: compress Cartesian tree into 64-bits integer
		      \State $\tt{LOGS} = 4$
		      \State $\tt{POWS} = 2^{\tt{LOGS}}$
		      \State int $D[POWS+1]$, $Dp = 0$;
		      \State uint64\_t $tmask$ = $0$
		      \State $D[0]$ = SHRT\_MAX
		      \For{$i = 1$ to $\tt{POWS}$} 
		        \State $v = A[i]$;
		        \State $cnt = 0$;
		        \While{$D[Dp] < v$}
		          \State $Dp = Dp-1$
		          \State $cnt = cnt + 1$
		        \EndWhile
		        \State $Dp = Dp+1$
		        \State $D[Dp] = v$
		        \State $tmask = tmask | ((cnt)<<((i-1)<<2))$
		      \EndFor
		      \State return $tmask$
		  \end{algorithmic}
      \end{algorithm}
    \end{minipage}%
    }
  \end{center}
\end{frame}

\begin{frame}
    \begin{center}
    \scalebox{0.6}{
    \begin{minipage}{1.5\linewidth}
      \begin{algorithm}[H]
        \caption{Range Minimum Query in 64-bits Cartesian Tree}
		  \label{alg:cacheObliviousQuery}
		  \begin{algorithmic}[1]
		    \Require
		      $\textit{tmask}$: 64-bits Cartesian tree;
		      $[l, r]$: query interval between $l$ and $r$
		    \Ensure 
		      $\textit{minIdx}$: the index of the minimum value in interval
		    \State int $\textit{minIdx}$ = $l$, $x$ = $0$;
		    \For{$l = l+1$ to $r$}
		      \State $x$ = $x+1 - ((tmask>>(l<<2))\&15)$
		      \If{$x \le 0$}
		        \State $\textit{minIdx}$ = $l$
		        \State $x$ = $0$
		      \EndIf
		    \EndFor
		    \State return $\textit{minIdx}$
		  \end{algorithmic}
      \end{algorithm}
    \end{minipage}%
    }
  \end{center}
\end{frame}

\begin{frame}
    \begin{center}
    \scalebox{0.6}{
    \begin{minipage}{1.5\linewidth}
      \begin{equation}
		  \begin{split}
		    &\mathit{LCA}(n, \mathit{tid}, p, q) \\
		      &= \left\{\begin{matrix*}[l]
		        \mathit{LCA}(\mathit{lsz}, \mathit{lid}, p, q) &&, p \le q < \mathit{lsz}\\ 
		        \mathit{LCA}(\mathit{rsz}, \mathit{rid}, p-\mathit{lsz}-1, q-\mathit{lsz}-1)+\mathit{lsz}+1 &&, 
		            \mathit{lsz} \le p \le q < n \\ 
		        \mathit{lsz} && , 0 \le p \le \mathit{lsz}, \mathit{lsz} \le q \le i\\ 
		        -1 && ,\mathit{otherwise}
		      \end{matrix*}\right.
		  \end{split}
		\end{equation}
    \end{minipage}%
    }
  \end{center}
\end{frame}

\begin{frame}
    \begin{center}
    \scalebox{0.6}{
    \begin{minipage}{1.5\linewidth}
      \begin{algorithm}[H]
  \caption{Get $tid$ from $\langle\mathit{lsz},\mathit{lid},\mathit{rsz},\mathit{rid}\rangle$ in $\theta(1)$ time}
  \label{alg:FunctionTid}
  \begin{algorithmic}[1]
    \Require
      $\langle\mathit{lsz},\mathit{lid},\mathit{rsz},\mathit{rid}\rangle$: size and label in left/right subtree
    \Ensure
      $\mathit{tid}$: this label
    \If{$\mathit{rsz} = 0$}
      \State return $\mathit{lid}$
    \EndIf
    \State $n = \mathit{lsz}+\mathit{rsz}+1$
    \State $\mathit{base} = 0$
    \For{$i=0$ to $\mathit{lsz}-1$}
      \State $\mathit{base}$ += $C_i \cdot C_{n-i-1}$
    \EndFor
    \State $\mathit{offset}$ = $\mathit{lid} \cdot C_{\mathit{rsz}}$ + $\mathit{rid}$
    \State return $\mathit{base}$ + $\mathit{offset}$
  \end{algorithmic}
      \end{algorithm}
    \end{minipage}%
    }
  \end{center}
\end{frame}

\begin{frame}
    \begin{center}
    \scalebox{0.6}{
    \begin{minipage}{1.5\linewidth}
      \begin{algorithm}[H]
  \caption{Parallel Algorithm for building LCA}
  \label{alg:parallelLCA}
  \begin{algorithmic}[1]
    \Require
      $s$: Maximum size for required the number of BST
    \For{$n = 1$ to $s$}
      \ParFor{$\mathit{tid} = 0$ to $C_n - 1$}
        \ParFor{$p = 0$ to $n-1$}
          \State compute $\langle\mathit{lsz},\mathit{lid},\mathit{rsz},\mathit{rid}\rangle$ in $O(n)$
          \For{$q = p$ to $n-1$}
            \State LCA[$n$][$\mathit{tid}$][$p$][$q$] = $\cdots$ ~\ref{fig:formulaLCA}
          \EndFor
        \EndParFor
      \EndParFor
    \EndFor
  \end{algorithmic}
      \end{algorithm}
    \end{minipage}%
    }
  \end{center}
\end{frame}

\begin{frame}
    \begin{center}
    \scalebox{0.6}{
    \begin{minipage}{1.5\linewidth}
      \begin{algorithm}[H]
  \caption{Offline Type of Cartesian Tree}
  \label{alg:typeOfCartesianOffline}
  \begin{algorithmic}[1]
    \Require
      $A[1 \cdots s]$: storage array;
      $s$: the number of elements;
    \Ensure
      $\mathit{tid}$: this label
    \State $\langle\mathit{lsz},\mathit{lid},\mathit{value}\rangle$ $D$[$s+1$]
    \State Dp = 0
    \State $D$[0] = $\langle0,0,\infty\rangle$
    \For{$i = 1$ to $s$}
      \State v = $A$[i], lsz = 0, lid = 0
      \While{$D$[Dp].value < v}
        \State lid = tid($D$[Dp].lsz, $D$[Dp].lid, lsz, lid)
        \State lsz += $D$[Dp].lsz + 1
        \State Dp = Dp - 1
      \EndWhile
      \State Dp = Dp + 1
      \State $D$[Dp] = $\langle\mathit{lsz},\mathit{lid},\mathit{v}\rangle$
    \EndFor
    \State lsz = 0, lid = 0
    \While{Dp > 0} // pop all
      \State lid = tid($D$[Dp].lsz, $D$[Dp].lid, lsz, lid)
      \State lsz += $D$[Dp].lsz + 1
      \State Dp = Dp - 1
    \EndWhile
    \State return lid
  \end{algorithmic}
      \end{algorithm}
    \end{minipage}%
    }
  \end{center}
\end{frame}

\begin{frame}
    \begin{center}
    \scalebox{0.6}{
    \begin{minipage}{1.5\linewidth}
      \begin{algorithm}[H]
  \caption{Online Type of Cartesian Tree}
  \label{alg:typeOfCartesianOnline}
  \begin{algorithmic}[1]
  \Require
      $\mathit{state}$: state of Cartesian Tree;
      $v$: the value which append to array
  \Ensure
      $\mathit{tid}$: this label
  \State Dp = state.Dp, lsz = lid = 0
  \State bsz = state.s - state.i + 1
  \State bid = C[bsz] - 1 
  \While{state.D[Dp].value < v}
    \State lid = tid(state.D[Dp].lsz, state.D[Dp].lid, lsz, lid)
    \State bid = tid(state.D[Dp].lsz, state.D[Dp].lid, bsz, bid)
    \State lsz = lsz + state.D[Dp].lsz+1
    \State bsz = bsz + state.D[Dp].lsz+1
    \State Dp = Dp - 1
  \EndWhile
  \State Dp = Dp + 1
  \State state.D[Dp] = <lsz,lid,v>, state.Dp = Dp
  \State state.tid = state.tid + bid - tid(lsz, lid, state.s-state.i, C[state.s-state.i]-1)
  \State state.i = state.i + 1
  \State return state.tid
  \end{algorithmic}
      \end{algorithm}
    \end{minipage}%
    }
  \end{center}
\end{frame}


\begin{frame}
    \begin{figure}[!thb]
      \centering
      \subfigure[Cartesian Tree Encoding]{
       	\includegraphics[scale=0.5]{graphics/fig-cartesian-encoding.pdf}
      }
      \label{fig:cartesianEncoding}
    \end{figure}
\end{frame}

\begin{frame}
	\frametitle{Workload Imbalance}
	\begin{itemize}
		\setlength\itemsep{1em}
		\item Disjoint set has a lot of indirect jumps, and it leads cache miss penatly.
		\item Due to the compensatory hardware threading and L2 cache layout, affinity 
			is important on the MIC. We can control of thread affinity via \tt{KMP\_AFFINITY}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Improve Workload (TODO)}
	\begin{itemize}
		\setlength\itemsep{1em}
		\item Reduce cache miss
			\begin{itemize}
			 	\item Relayout data of disjoint set: structure of array, 
			 		array of structure, hybrid combinations, or ...
			 	\item Software caches
			 	\item Data compression
			 	\item Dynamic data layout
			\end{itemize}
		\item Reduce indirect jumps
			\begin{itemize}
				\item The policy of path compression / union by rank
				\item Lazy propagation
			\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Exploit Parallelism (TODO)}
	\begin{itemize}
		\setlength\itemsep{1em}
		\item Using rank convergence in dynamic programming algorithm
			\footnote{Saeed Maleki, Efficient Parallelization Using Rank Convergence in 
				Dynamic Programming Algorithm, Microsoft, 2016}
		\item Simultaneously, it reduces memory usage on a single processor,
			less cache miss penalty will be faster(?).
	\end{itemize}
\end{frame}

\subsection{Serial part-VG LCS Algorithm (TODO)}
\begin{frame}
	\frametitle{Serial part-VG LCS Algorithm}
\end{frame}

\subsection{Parallel part-VG LCS Algorithm (TODO)}
\begin{frame}
	\frametitle{Parallel part-VG LCS Algorithm}
	\begin{itemize}
		\item Maybe we can change the definition of recursion formula to exploit the efficiency of the parallelism, like this paper
		\footnote{Jiaoyun Yang, An Efficient Parallel Algorithm for Longest Common Subsequence Problem on GPUs, 2010}.
	\end{itemize}
\end{frame}

\subsection{Parallel ELVGLCS (TODO)}
\begin{frame}
	\frametitle{Parallel ELVGLCS (TODO)}
	\begin{itemize}
		\item High memory usage 
			\begin{itemize}
				\item Compression
			\end{itemize}
	\end{itemize}
\end{frame}

\subsection{Optimization (TODO)}
\begin{frame}
	\frametitle{Optimization (TODO)}
	\begin{itemize}
		\setlength\itemsep{1em}
		\item Coalesced memory access or memory coalescing
			\begin{itemize}
				\item Doubling algorithm creates smaller table
					and uses more computation in query.
			\end{itemize}
		\item Loop fission / fusion: improve data locality, 
			but maybe increase thread overhead.
		\item Data preprocessing about the boundary of computation: use a simple dynamic programing to solve it before paralleling serial algorithm
	\end{itemize}
\end{frame}