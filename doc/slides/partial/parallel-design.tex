\section{Parallel Design}

\subsection{Data Structure}
\begin{frame}
    \frametitle{Online Data Structure}
    \begin{itemize}
    \setlength\itemsep{1em}
    	\item Incremental Suffix Maximum Query
    		\begin{itemize}
    			\setlength\itemsep{1em}
    			\item Binary Indexed Tree (Fenwick Tree): $\mathcal{O}(\log n)$
    			\item Segment Tree: $\mathcal{O}(\log n)$
    			\item Van Emde Boas Tree: $\mathcal{O}(\log \log n)$
    			\item Disjoint Set: $\Omega(\alpha(n))$
    			\item Sparse Table: $\mathcal{O}(n \log n)$ -- $\mathcal{O}(1)$
    		\end{itemize}
    	\item Which one is cache-friendly/ exploit parallelism easily?
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Offline RMQ Data Structure}
    \begin{itemize}
    \setlength\itemsep{1em}
    	\item Cache-oblivious cartesian tree
    	\footnote{Erik D. Demaine, On Cartesian Trees and Range Minimum Queries, MIT, 2009}
    	\item Parallel cartesian tree algorithm:  $\mathcal{O}(\frac{n}{p} \log^2 n + d)$, 
    		which $d$ is the maximum depth of the cartesian tree.
    	\footnote{Julian Shun, A Simple Parallel Cartesian Tree Algorithm and its Application 
    		to Parallel Suffix Tree Construction, Carnegie Mellon University, 2014}
    \end{itemize}
\end{frame}

\subsection{Parallel VGLCS}
\begin{frame}
	\frametitle{Data Dependency (TODO)}
	\begin{itemize}
		\setlength\itemsep{1em}
		\item We want to remove \texttt{All[i][j]} because its data dependency 
			is hard to parallel.
		\item The $O(n \log n)$ -- $O(1)$ sparse table is a good alternative plan. 
			However, parallel algorithm will be $O((n^2 \log n) / p + n \log n)$ with $p$ processors.
		\item Cache-oblivious sparse table run $O(n)$ -- $O(1)$ 
			with extra space $O(n)$ which record catalan number.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Data Layout (TODO)}
	\begin{itemize}
		\setlength\itemsep{1em}
		\item Dynamic data relocation improve the data locality
		\item Design auxiliary structure like fractional cascading
		\footnote{Churchill Navigation's Programming Challange 2015 \url{https://www.zhihu.com/question/27729745}}
		\item Use \textbf{van Emde Boas} layout whose leaves point to intervals in a packed memory structure.
		\footnote{MIT: Cache-Oblivious Search Trees Project \url{http://supertech.csail.mit.edu/cacheObliviousBTree.html}}
		\footnote{Gerth Stolting Brodal, Cache Oblivious Search Tree via Binary Trees of Small Height, 1999}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Serial VGLCS Algorithm (TODO)}
	If the length of two sequences are $n$, it runs in $\mathcal{O}(\mathcal{R} \; \alpha(n)))$ 
	from reference paper, which $\mathcal{R} = O(n^2)$. \\

	We have a better algorithm as follows:
	\begin{itemize}
		\setlength\itemsep{1em}
		\item Gernerate all structurally unique binary search tree, then compute the LCA of all pairs. 
			It uses $\theta(\sum_{i = 1}^{s} i^2 C_i)$ space.
			(Catalan number $C_n = \frac{1}{n+1} \binom{2n}{n} \sim \frac{4^n}{n^{1.5}}$)
		\item Use cache-oblivious sparse table, it runs in $\mathcal{\theta}(n^2)$.
			It is theoretically possible.
		\footnote{Johannes Fischer, V.H., A new succinct representation of 
				RMQ-information and improvements in the enhanced suffix array, 2007}
		\footnote{Masud Hasan, Cache oblivious algorithms for the RMQ and the RMSQ problems, 2010}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Parallel VGLCS Algorithm (TODO)}
	How to parallel our better algorithm?
	\begin{itemize}
		\setlength\itemsep{1em}
		\item We need to pre-process all unique binary search trees with $[1, s]$ nodes,
			so the time complexity is at least $\theta(\sum_{i = 1}^{s} i^2 C_i) =  \theta(?)$.
		\item Finally, it runs in $O(?/p + \log \frac{n}{\log n}) = O(?/p + \log n)$ in parallel.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Parallel VGLCS Algorithm (TODO)}
	Alternative plan for the above algorithm is using hybrid data structure.
	We can combine disjoint-set, sparse table, and cache-oblivious cartesian tree together.
	\begin{itemize}
		\setlength\itemsep{1em}
		%\item Disjoint-set: $\mathcal{O}(\frac{1}{p}(\mathcal{R} \; \alpha(n)))$.
		\item Sparse table with cartesian tree: $\mathcal{\theta}(\frac{n}{p} (n/s) \log (n/s))$.  
		We pick $s = \frac{\log n}{4}$, and time complexity is $\mathcal{\theta}(n/p + \log n)$ -- $\mathcal{O}(s)$.
		\item Most interval queries can be divided into two block queries
			and one superblock-query, and each query is $O(1)$. 
			Otherwise, inblock query is $O(s)$
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Workload Imbalance}
	\begin{itemize}
		\setlength\itemsep{1em}
		\item Disjoint set has a lot of indirect jumps, and it leads cache miss penatly.
		\item Due to the compensatory hardware threading and L2 cache layout, affinity 
			is important on the MIC. We can control of thread affinity via \tt{KMP\_AFFINITY}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Improve Workload (TODO)}
	\begin{itemize}
		\setlength\itemsep{1em}
		\item Reduce cache miss
			\begin{itemize}
			 	\item Relayout data of disjoint set: structure of array, 
			 		array of structure, hybrid combinations, or ...
			 	\item Software caches
			 	\item Data compression
			 	\item Dynamic data layout
			\end{itemize}
		\item Reduce indirect jumps
			\begin{itemize}
				\item The policy of path compression / union by rank
				\item Lazy propagation
			\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Exploit Parallelism (TODO)}
	\begin{itemize}
		\setlength\itemsep{1em}
		\item Using rank convergence in dynamic programming algorithm
			\footnote{Saeed Maleki, Efficient Parallelization Using Rank Convergence in 
				Dynamic Programming Algorithm, Microsoft, 2016}
		\item Simultaneously, it reduces memory usage on a single processor,
			less cache miss penalty will be faster(?).
	\end{itemize}
\end{frame}

\subsection{Serial part-VG LCS Algorithm (TODO)}
\begin{frame}
	\frametitle{Serial part-VG LCS Algorithm}
\end{frame}

\subsection{Parallel part-VG LCS Algorithm (TODO)}
\begin{frame}
	\frametitle{Parallel part-VG LCS Algorithm}
	\begin{itemize}
		\item Maybe we can change the definition of recursion formula to exploit the efficiency of the parallelism, like this paper
		\footnote{Jiaoyun Yang, An Efficient Parallel Algorithm for Longest Common Subsequence Problem on GPUs, 2010}.
	\end{itemize}
\end{frame}

\subsection{Parallel ELVGLCS (TODO)}
\begin{frame}
	\frametitle{Parallel ELVGLCS (TODO)}
	\begin{itemize}
		\item High memory usage 
			\begin{itemize}
				\item Compression
			\end{itemize}
	\end{itemize}
\end{frame}

\subsection{Optimization (TODO)}
\begin{frame}
	\frametitle{Optimization (TODO)}
	\begin{itemize}
		\setlength\itemsep{1em}
		\item Coalesced memory access or memory coalescing
			\begin{itemize}
				\item Doubling algorithm creates smaller table
					and uses more computation in query.
			\end{itemize}
		\item Loop fission / fusion: improve data locality, 
			but maybe increase thread overhead.
		\item Data preprocessing about the boundary of computation: use a simple dynamic programing to solve it before paralleling serial algorithm
	\end{itemize}
\end{frame}