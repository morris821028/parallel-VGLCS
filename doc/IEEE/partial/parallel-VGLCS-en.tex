\section{Parallel VGLCS Algorithm} %
\label{sec:parallelVGLCS}

\input{algorithms/alg-serial-VGLCS}

The serial VGLCS algorithm~\ref{alg:serial-VGLCS} by
Peng~\cite{Peng2011TheLC} and other variants of LCS are difficult to
parallelize.  These algorithms use several states to determine a new
state during dynamic programming.  This construction requires {\em
  heavy data dependency}, and makes it difficult to parallelize the
computation in a naive row-by-row manner.  If we parallel Peng's
algorithm with wavefront method intuitively, it will require extra
space to record all row status, which is not required in the origin
algorithm.  On the other hand, if we use the
Maleki's~\cite{Maleki2016EfficientPU} technique, it also uses extra
space to maintain state translation, and spends more time to merge
split parts.  Therefore, it is crucial that our parallelization
conserves both memory and time.

In order to find VGLCS efficiently, we need to address the {\em
  incremental suffix maximum query} (ISMQ) problem, which was
proposed by Peng~\cite{Peng2011TheLC}.  A data structure that supports
incremental suffix maximum queries should support the following three
operations.  First, a {\tt make} operation creates an empty array $A$.
Second, an {\tt append(V)} operation appends a value $V$ to array $A$.
Finally an ISMQ {\tt query(x)} finds the {\em maximum} value among the
$x$-th value to the end of an array $A$.

The sequential version of Peng's algorithm has two stages.  In the
first stage, the algorithm uses a {\em disjoint set} to efficiently
answer ISMQ to compute the answer on every column, which form an array
$S$.  In the second stage, the algorithm again uses ISMQ on array $S$
obtained from the first stage to get the final answers.

Peng uses a {\em disjoint-set} data structure to answer incremental
suffix maximum queries, and finds a VGLCS with answers from ISMQ. The
disjoint-set data structure by Gabow~\cite{Gabow1983ALA} and
Tarjan~\cite{Tarjan1975EfficiencyOA} solves the {\em union-and-find
problem}.  The amortized time per union/find operation is
$O(\alpha(n))$.

However, a disjoint set implementation of Peng's algorithm is difficult
to parallelize for two reasons.  First, the query in the second stage
will change the data structure because the lookup operation will
compress the path to the root, so it is difficult to maintain a
consistent view of the data structure when multiple processing units are
compressing the path simultaneously.  Second, in the first stage when
multiple processing units are compressing different paths, the load
among them could very different, and incurs load imbalance.  Third, in
the first stage there will be a large number of threads that work on
different part of the disjoint-set forests, therefore it will be
difficult to synchronize them efficiently.

Since the disjoint set cannot support ISMQ efficiently in parallel, we
consider the following data structures to support ISMQ efficiently in
parallel.

\begin{itemize}
  \item Segment tree~\cite{berg2000computational} supports ranged
    maximum query and update in multi-dimensions.  The time complexity
    of both update and query is $O(\log n)$ in one-dimension.
  \item Sparse table~\cite{Berkman1993RecursiveSP} requires a $O(n
    \log n)$ preprocessing, and can support ranged maximum query in
    $O(1)$ time in one dimensional data.  A sparse table is a two
    dimensional array.  The element of a sparse table in the $j$-th
    row and $i$-th column is the maximum among the $i$-th elements
    and its $2^j - 1$ predecessors in the input array.
\end{itemize}

\begin{figure}[!thb]
  \centering \subfigure[Array]{
    \includegraphics[width=\linewidth]{graphics/fig-interval-decomposition-origin.pdf}
    \label{fig:fig-interval-decomposition}
  } \subfigure[Sparse Table]{
    \includegraphics[width=\linewidth]{graphics/fig-sparse-table-origin.pdf}
    \label{fig:fig-sparse-table}
  }
  \caption{A sparse table example}
  \label{fig:interval-decomposition}
\end{figure}

We give an example of the sparse table.  The input is in array $A$. We
split array $A$ into five blocks so that each block has four elements.
The we build a sparse table $ST$ on $A$ as described earlier.  Now a
ranged maximum query on $A$ can be answered by at most two queries
into the sparse table.  For example, if the query is of the range from
2 to 13, then the answer is the maximum of the two answers -- one from
2 to 9, and one from 6 to 13.

We now present a simple version of our parallel VGLCS algorithm.  The
algorithm uses a sparse table and its time complexity is $O(n^2 \log n
/ p + n \log n)$, where $p$ is the number of processors.  In
Section~\ref{sec:parallelIRMQ}, we present a more complicated version
that uses a variant of the sparse table, and runs in $O(n^2 / p + n
\log n)$.

% say something about how to parallelize the Peng's algorithm with
% sparse table.

% say something about the advantage of using sparse table, instead of
% disjoint set

The pseudo code of our simple version parallel algorithm is in
Algorithm~\ref{alg:parallel-VGLCS}

\input{algorithms/alg-parallel-VGLCS}
