\section{Parallel VGLCS Algorithm with Sparse Table} %
\label{sec:parallelVGLCS}

% use line number in the following to explain the idea.

We first describe a naive dynamic programming for VGLCS.  Let $A$ and
$B$ denote the two input strings of length $n$ and $m$ respectively,
$G_A$ and $G_B$ be the arrays of the variable gap constraints, and
$V[i, j]$ be the maximum length of the variable gapped longest common
subsequence between substring $A[1, i]$ and $B[1, j]$.  A naive
algorithm finds $V[i, j]$ by finding the {\em maximum} within the
rectangle $V[i-G_A(i)-1 \cdots i-1, j-G_B(j)-1 \cdots j-1]$.  Please
refer to Figure~\ref{fig:fig-VGLCS-dp-naive} for an illustration.

\begin{figure}[!thb]
  \includegraphics[width=0.40\linewidth]{\GraphicPath/fig-VGLCS-dp-naive.pdf}
  \caption{How to compute $V$.}
  \label{fig:fig-VGLCS-dp-naive}
\end{figure}

The computation of $V$ can be optimized as follows.  Note that the
computation of $V[i, j]$'s with the same $i$ has the same gap
constraint $G_A(i)$, so the maximum within the rectangle can be
computed by combining the results from several queries on the maximum
of the {\em suffix} in the $i$-row of $V$.  Please refer to
Figure~\ref{fig:fig-VGLCS-dp} for an illustration.  Note that these
maximum queries on the suffix are {\em incremental} in a sense that
the computation on the next $V[i, j + 1]$, if done carefully, can
reuse most of the results from the computation of $V[i, j]$.  We will
refer to this type of queries as {\em incremental suffix maximum
  query}, i.e., we would like to maintain a data structure form which
we can find the maximum of its suffix efficiently while we add data at
its end.

\begin{figure}[!thb]
  \includegraphics[width=0.40\linewidth]{\GraphicPath/fig-VGLCS-dp.pdf}
  \caption{Compute $V$ with incremental suffix maximum queries.}
  \label{fig:fig-VGLCS-dp}
\end{figure}

The sequential VGLCS algorithm~\ref{alg:serial-VGLCS} by
Peng~\cite{Peng2011TheLC} applies the optimization and is shown as
Algorithm~\ref{alg:serial-VGLCS} below.  The outer loop goes through
every row, and the inner loop goes through every element of a row from
left to right.  We use an array of $C$ to answer incremental maximum
queries on all columns.  That is, we can think of $C[j]$ as a data
structure that supports incremental suffix maximum queries on the
$j$-th column of $V$.  From the previous observation that all
computation of elements in the $i$-th row of $V$ share the same gap
$G_A$, we will query each $C$ for the maximum in the suffix that ends
at row $i-1$ with length $G_A + 1$, and place these maximums in
another data structure $R$ that also supports incremental suffix
maximum queries.  It is easy to see that the value of $V[i][j]$ can be
obtained by querying $R$ with a suffix maximum query of length $G_B +
1$ as shown in Figure~\ref{fig:fig-VGLCS-dp}.

We update $V$, $C$, and $R$ as follows.  If the $i$-th character of
$A$ matches the $j$-th character of $B$ then $V[i][j]$ is the maximum
among the rectangle plus 1, as shown in Figure~\ref{fig:fig-VGLCS-dp}.
This maximum can be found by querying $R$ for the maximum among the
last $G_B[j]$ elements in it.  Note that $R$ contains the information
of the previous row, up to the element of the $j-1$ element.  After
that we add the maximum of last $G_B + 1$ in the $j$-the column into
$R$, and the newly computed $V[i][j]$ into $C[j]$, which supports
ISMQ on the $j$-the column, before going to column $j + 1$.  If the
$i$-th character of $A$ does {\em not} match the $j$-th character of
$B$ then we simple set $V$ to 0 since it does not affect the answer,
then again update $R$ accordingly.
 
\input{\AlgoPath/alg-serial-VGLCS-2e}


\subsection{Incremental Suffix Maximum Query}

From the previous discussion of Peng's algorithm, we note that in
order to find VGLCS efficiently, we need to address the {\em
  incremental suffix maximum query} (ISMQ) problem.  A data structure
that supports incremental suffix maximum queries should support the
three operations.  First, a {\tt make} operation creates an empty
array $A$. Second, an {\tt append(V)} operation appends a value $V$ to
array $A$. Finally an ISMQ {\tt query(x)} finds the {\em maximum}
value among the $x$-th value to the end of an array $A$.

Peng uses a {\em disjoint-set} data structure to answer incremental
suffix maximum queries in his VGLCS algorithm.  The disjoint-set data
structure was proposed by Gabow~\cite{Gabow1983ALA} and
Tarjan~\cite{Tarjan1975EfficiencyOA} to solves the {\em union-and-find
  problem}.  The set of data are stored in a sequence of disjoint
sets, and maintain the property that the {\em maximum} of disjoint
sets are at the root and in {\em decreasing} order.  When we add a
value $x$ into the data structure, we put it at the end as a set of
itself.  Then we start joining (with union operation) from the last
set to its previous set until the maximum of the previous set is {\em
  larger}.  It is easy to see that the {\tt query(x)} operation is
simply a {\em find} operation that finds the root, which has the {\em
  maximum}, of the tree that $x$ belongs to.  The amortized time per
union/find operation is $O(\alpha(n))$.

\subsection{A Parallel VGLCS Algorithm}

The sequential VGLCS algorithm~\ref{alg:serial-VGLCS} by
Peng~\cite{Peng2011TheLC} and other variants of LCS are difficult to
parallelize.  These algorithms use several states to determine a new
state with a dynamic programming.  This construction requires {\em
  heavy data dependency}, and is difficult to parallelize in a naive
row-by-row manner because an element of the dynamic table needs the
values of elements in the same row to compute its value.  On the other
hand, if we parallelize Peng's algorithm with the wavefront method, it
will require {\em extra space} to record all row status, % what status??
which is not required in the the sequential algorithm.

% On the other hand, if we use the
% Maleki's~\cite{Maleki2016EfficientPU} technique, % need to explain this technique
% it also uses extra
% space to maintain state translation, and spends more time to merge
% data.  Therefore, it is crucial that our parallelization conserves
% {\em both} memory and time.

% It seems that you should use the new figures to explain these???
% Morris: how to make it to row-by-row manner

We propose a parallel VGLCS algorithm with an optimized row-by-row
approach that removes the data dependency among elements within the
same row.  We adopt the row-by-row approach for two reasons.  First,
we observe that the length of the critical path of a wavefront method
is greater than that of a row-by-row method.  Second, if we can
removes the data dependency among elements within the same row, then
the computation on the elements of the same row can be fully
parallelized.

A sketch of our algorithm is as follows.  The algorithm will compute
$V$ one row at a time.  The computation of each row has two stages.
In the first stage, the algorithm queries the $C$'s {\em in parallel}
to obtain the maximums of suffix of length $G_A + 1$ and place them
into an array $A$.  Recall from Algorithm~\ref{alg:serial-VGLCS} that
$C$ is the data structure in every column that supports incremental
suffix maximum on $V$.  Please refer to
Figure~\ref{fig:fig-VGLCS-dp-rmq} for an illustration.  Then in the
second stage, the algorithm uses {\em range maximum query} on $A$ to
compute the all elements in the $i$-th row of $V$ {\em in parallel}.
<<<<<<< .mine
Note that since we compute all element in the $i$-th row of $V$ in
=======
Note that since we compute all elements in the $i$-th row of $V$ in
>>>>>>> .r17522
parallel, we cannot query the suffix of $A$, and instead we need to
query a range of $A$ for the maximum.  Please refer to
Figure~\ref{fig:fig-VGLCS-dp-rmq} for an illustration.  Note that we
need to update $C$'s {\em incrementally} so that they contain the
information of the $i$-th row of $V$ we just computed.  Also since the
algorithm iterates in rows, so $C$ only needs to support suffix
maximum query.

\begin{figure}
  \includegraphics[width=0.82\linewidth]{\GraphicPath/fig-VGLCS-dp-rmq.pdf}
  \caption{Two stages of the computation of one row of $V$.}
  \label{fig:fig-VGLCS-dp-rmq}
\end{figure}

To resolve the data dependency we need to consider a good data
structure that can handle incremental suffix/range maximum query {\em
  in parallel}.  We note that it is {\em not} feasible to parallelize
the disjoint set implementation for three reasons.  First, a query for
disjoint set will change the data structure because the lookup will
{\em compress} the path to the root.  It is difficult to maintain a
consistent view of the data structure when multiple processing units
are compressing the path {\em simultaneously}.  Second, when multiple
processors are compressing different paths, the load among them could
be very different, and this will incur load imbalance. Third, there
will be a large number of threads working on different part of the
disjoint-set, therefore it will be difficult to synchronize them
efficiently.

\subsection{Sparse Table}

Since the disjoint set cannot be implemented efficiently in parallel,
we use the sparse table to support incremental suffix/range maximum
queries.  Sparse table~\cite{Berkman1993RecursiveSP} requires a $O(n
\log n)$ preprocessing, and can support range maximum query in $O(1)$
time on one dimensional data.  A sparse table is a two dimensional
array.  The element of a sparse table in the $j$-th row and $i$-th
column is the maximum among the $i$-th elements and its $2^j - 1$
predecessors in the input array.

We give an example of the sparse table
(Figure~\ref{fig:interval-decomposition}).  The input is in array
$A$. We split array $A$ into five blocks so that each block has four
elements.  The we build a sparse table $ST$ on $A$ as described
earlier.  Now a ranged maximum query on $A$ can be answered by at most
{\em two} queries into the sparse table.  For example, if the query is
of the range from 2 to 13, then the answer is the maximum of the two
answers -- one from 2 to 9, and one from 6 to 13.

\begin{figure}[!thb]
  \centering \subfigure[Array]{
    \includegraphics[width=0.45\linewidth]{\GraphicPath/fig-interval-decomposition-origin.pdf}
    \label{fig:fig-interval-decomposition}
  } \subfigure[Sparse Table]{
    \includegraphics[width=0.45\linewidth]{\GraphicPath/fig-sparse-table-origin.pdf}
    \label{fig:fig-sparse-table}
  }
  \caption{A sparse table example}
  \label{fig:interval-decomposition}
\end{figure}

It is easy to see that one can build a sparse table in parallel
efficiently.  Please refer to
Algorithm~\ref{alg:parallel-sparse-table} for details.  Our parallel
sparse table implementation in
Algorithm~\ref{alg:parallel-sparse-table} runs in only $O(n \log n / p
+ \log n)$, where $n$ is the number of elements and $p$ is the number
of processors, and is very easy to parallelize and to implement.

\input{\AlgoPath/alg-parallel-sparse-table-2e}

\subsection{Parallel VGLCS with Sparse Table}

We now present a simple version of our parallel VGLCS algorithm with
sparse table.  The time complexity is $O(n^2 \log n / p + n \log n)$,
where $p$ is the number of processors.  In
Section~\ref{sec:parallelIRMQ}, we will present a more complicated
version that uses a variant of the sparse table, and runs in $O(n^2 /
p + n \log n)$.

The operations on a sparse table are much easily to parallelize than
those on a disjoint set, which is used within the inner loop of Peng's
sequential VGLCS algorithm.  The inner loop of Peng's algorithm
alternates between append and query operations on $R$.  Please refer
to Algorithm~\ref{alg:serial-VGLCS} for details.  This alternation
between appending and querying incurs heavy data dependency.  In
addition, the parallelism of operations on a disjoint tree is limited
by the length of path under compression.  The length is usually very
short and provide very limited parallelism.

The pseudo code of our simple version parallel VGLCS algorithm using
sparse table is given in Algorithm~\ref{alg:parallel-VGLCS}.  The
algorithm computes $V$ one row at a time.  The computation of each row
has two stages.  In the first stage, the algorithm queries the $C$'s
{\em in parallel} to obtain the maximums of suffix of length $G_A + 1$
and place them into an array $M$, and build a sparse table $T$ with
the data of $M$.  Then in the second stage, the algorithm query $T$ to
find the range maximum in $M$ to compute the all elements in the
$i$-th row of $V$ {\em in parallel}.

\input{\AlgoPath/alg-parallel-VGLCS-2e}



