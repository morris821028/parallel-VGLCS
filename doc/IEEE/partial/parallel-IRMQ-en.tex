\section{Parallel Range Maximum Query}
\label{sec:parallelRMQ}

\subsection{Background}

Even though we parallel origin serial algorithm successfully, the
theoretical time complexity of VGLCS algorithm is limited by the range
maximum/minimum query in parallel.  In VGLCS problem, each stage has
$n$ elements and $n$ numbers of the range query.  We should let pre-
processing and query time minimize.  The most of the tree structures
cannot show efficient performance in both pre-processing and query
time.  Some offline algorithm is too hard to parallel.  In this
section, we provide the solution to get better performance in both
pre-processing and query stage.

\iffalse
縱使我們已能很好地平行化原本的序列算法，在理論複雜度上受限於平行下的區間極值查詢 (Range Minimum/Maximum Query, RMQ)。
在這個應用中，每一階段有 $n$ 個元素和 $n$ 個區間詢問。
這樣的條件下，大部分樹狀結構難以在前處理過程和每次詢問皆達到最好效能。
對於 $O(n)$ -- $O(1)$ 操作的離線區間詢問無法提供平行。
再接續的小節中，我們將提出在兼顧建表、插入和查找的數據結構與算法。
\fi

\subsection{Compressed Cartesian Tree}

In Fischer ~\cite{Fischer2006TheoreticalAP} paper, the $O(n)$ --
$O(1)$ algorithm is corrponding by $C_s$, where $C_s$ is the $s$-th
Catalan number  and $C_s = \frac{1}{s+1}\binom{2s}{s} =
O(\frac{4^s}{s^{1.5}})$ to build look-up table.  When we c hoose $s =
\frac{1}{4} \log n$ as block size, the space complexity is $O(s^2
\frac{4^s}{s^{1.5}}) = O(n)$, and time complexity is $O(n)$.  Each
range query will be split into 4 parts, 2 super-block queries and 2
in-block queries.  It need to 4 time memory access.  We give a example
in the figure ~\ref{fig:interval-decomposition}.  In the offline RMQ
problem, it has the theoretical algorithm which run in $O(n)$ --
$O(1)$ time.  When $n$ is large, four-time memory access caused the
serious cache miss. In order to improve cache miss, Demaine introduced
the cache- oblivious the algorithm in Cartesian tree
~\cite{Demaine2009OnCT}.

\iffalse
在 Fischer \cite{fischer} 的論文中，
根據卡塔蘭數 $\frac{1}{s+1}\binom{2s}{s} = O(\frac{4^s}{s^{1.5}})$ 建立查找表 (lookup-table)，
其中選擇 $s = \frac{1}{4} \log n$ 時，空間複雜度 $O(s^2 \frac{4^s}{s^{1.5}}) = o(n)$ 且建表複雜度 $o(n)$。
每一個區間詢問將會拆成 2 個 super-block 和 2 個 in-block 詢問，共計需要 4 次的記憶體存取。
在理論分析上，離線 RMQ 問題可在 $\theta(n)$ -- $\theta(1)$ 時間內解決任一詢問。
當 $n$ 越大時，這 4 次的記憶體存取會遭遇到嚴重的快取未中 (cache miss)，
在 Demaine ~\cite{demaine} 的論文中，發展出快取忘卻 (cache oblivious) 形式的查找方案，
降低在離線版本中的 in-block 詢問產生的快取未中。
\fi

In above technology, we parallel RMQ problem by Fischer's idea and get
time complexity $O(n / p + \log n)$ -- $O(1)$ algorithm.  We also
combine compression skill from Demaine's paper. It reduces cache-miss
and run in ideal complexity.

\iffalse
在上述的技術中，我們可以藉由 Fischer 提出的方案平行化 RMQ 至 $O(n / p + \log n)$ -- $O(1)$，使用 Demaine 提供的技巧壓縮空間使用量，降低快取未中以提升運行效能。這裡我們挑選固定長度的壓縮方案 $s = 16$，其能解決序列長度為 $n = 2^{64}$ 的區間查找，將 16 個整數壓縮成一棵笛卡爾樹。在第 $i$ 次插入時，左旋的次數 $l_i$，每次操作皆符合 $\sum_{i=1}^{n} l_i < i$。
\fi

We pick the fixed length $s = 16$, which can solve $n = 2^{64}$ one-
dimension range maximum query.  When inserting $i$-th elements, the
number of $i$-th insertion satisfy $\sum_{i=1}^{n} l_i < i$ where $0
\le l_i < s$ is the number of nodes remove from the rightmost path of
Cartesian tree.  Because all $l_i$ is small than 16, it can present in
4-bit integer.  Due to above property of Cartesian tree, we merger 16
4-bit integers into a 64-bit integer to present a Caartesian tree.
The compressed algorithm ~\ref{alg:cartesian-to-64bits} run in $O(s)$.

Finally, the appropriate size can compress the usage of space to
reduce cache miss and also show better performance in modern 64-bit
register.  We modify Demaine's range query algorithm as the algorithm
~\ref{alg:cartesian64bits-query}.

\iffalse
因所有 $l_i < 16$，使得每個 $l_i$ 可用 4-bit 表示之，
整體便可用 64-bit 長整數表示一棵笛卡爾樹的狀態。
為了現在常見的 64-byte 快取列 (cache line) 和 64-bit 暫存器 (register) 考量，
我們選用合適的大小進行測試，不僅壓縮空間使用量，同時也減少快取未中的問題。
最後，我們得到壓縮算法 \ref{alg:cartesian-to-64bits}，其相對應的區間查找算法，
根據 Demaine \cite{demaine} 進行修改，得到壓縮下的詢問算法 \ref{alg:cartesian64bits-query}。
\fi

\input{algorithms/alg-cartesian-to-64bits}

\input{algorithms/alg-cartesian64bits-query}

In VGLCS problem, above algorithm provide compression skill to reduce
cache miss, but increase the time complexity.  The pre-processing
spend $O(n)$ time, and single query spends $O(s)$ time in RMQ.
Totally, time complexity is $O(n^2 \; s / p + n \max(\log n, s))$.

\iffalse
回到 VGLCS 的應用中，上述算法使用壓縮方式降低快取未中。
我們可以使用上述的算法取代原先的并查集，建表的時間複雜度為 $O(n)$，
單一查詢的時間複雜度為 $O(s)$。
整體的時間複雜度為 $O(n^2 \; s / p + n \max(\log n, s))$。
\fi


%%%%%%%%%%%%%%

\section{Incremental Range Maximum Query}

In the VGLCS problem, we divide the algorithm into two stage, row and
column stage.  In the row stage, it maintains $m$ number of the data
structure to support ISMQ problem.  After row stage, the column stage
uses one ISMQ data structure to answer each query.

In parallel environment, the column stage has a linear algorithm which
use Fischer's sparse table instead of disjoint set, and we also
parallel its algorithm in theoretical $O(n / p + \log n)$ time, and
better performance algorithm in $O(n s / p + \log n)$ in section
~\ref{sec:parallelRMQ}.  Oppositely, the row stage has $m$ number of
independent data structure and run in amortized $O(n / p + 1)$ time.
In this section, we provide the new data structure to make row stage
run in more stable amortized $O(n / p + 1)$ time.   The final result
is presented on table ~\ref{tlb:cmp-complexity}.

\input{./tables/tlb-cmp-complexity.tex}

\subsection{Build Look-up Table}

We have two main subjects: cartesian tree encoding and cache
performance.  Fischer introduced the first encoding method and the
Masud presents the new encoding method and processing step to reduce
the number of instructions.  However, most of them focus on the
offline algorithm.  It means that there are given $n$ elements and
then has $m$ queries.  During any queries, the $n$ elements will not
be modified by any operation.

We could not use sorting to improve cache miss because the number of
elements and queries are similar.  However, we can still improve the
cache miss by design the special encoding method according to value
distribution.

In our application, we provide the online encoding algorithm.  We list
all binary search tree by lexicographical order and label them from
$0$ to Catalan $n$-th number.  The lexicographical order for binary
search tree is defined by the left subtree high priority and then
right subtree.  The figure \ref{fig:labelingBST} shows label of binary
search tree for the $n=1,2,3$ number of nodes.

\begin{figure}[!thb]
  \centering
  \includegraphics[width=\linewidth]{graphics/fig-bst-encoding.pdf}
  \caption{The label of each binary search tree}
  \label{fig:labelingBST}
\end{figure}

For the $s$ nodes binary search tree, we label node from $0$ to $s-1$
and the identify $\mathit{tid}$.  We define $\mathit{LCA}(s,
\mathit{tid}, p, q)$ as the lowest common ancestor of the node $p$ and
$q$ on a binary search tree which has $s$ nodes and labeling
$\mathit{tid}$, such as $\mathit{LCA}(3, 2, 0, 2) = 1$.

We define four variable
$\langle\mathit{lsz},\mathit{lid},\mathit{rsz},\mathit{rid}\rangle$,
which $\mathit{lsz}$ is the size of the left subtree, $\mathit{rsz}$
is the size of the right subtree, $\mathit{lid}$ is the identify of
the left subtree, and $\mathit{rid}$ is the identify of the right
subtree.  These four variables
$\langle\mathit{lsz},\mathit{lid},\mathit{rsz},\mathit{rid}\rangle$ is
decided by the identify of binary search tree $\mathit{tid}$ in
$O(s)$.  Finally, the formula \ref{fun:LCA} is shown for the lowest
common ancestor.

\input{./formulas/fun-LCA.tex}

In order to store all binary search trees, the space complexity is 

\begin{equation}
\theta\left(\frac{s^2}{s+1} \binom{2s}{s}\right) = \theta\left(n\right)
\end{equation}

, and the time complexity of parallel algorithm \ref{alg:parallel-LCA}
is

\begin{equation}
\theta\left(\frac{s^3}{s+1} \binom{2s}{s} \bigg/ p + s^2 \right)
\end{equation}.

\input{algorithms/alg-parallel-LCA.tex}

\subsection{Dynamic Cartesian Tree}

There are three intuitive solutions for ISMQ.  The first one uses
disjoint set which uses $O(\alpha(n))$ for each query.  The second one
uses sparse table which uses $O(\log n)$ time to append a new value to
the tail of array and $O(1)$ time to response a query.  The third one
is the binary indexed tree which used $O(\log n)$ time for each
operation.

In the sparse table, Fischer provide the $\theta(n)$ -- $\theta(1)$
could not support the append operation.  However, the sparse table
support RMQ problem is more powerful than suffix maximum value
problem.  In this section, we provide a solution to make the sparse
table to support the append operation.  The problem which is more
powerful than ISQM problem is named incremental range maximum query
(IRMQ).  IRMQ support two kinds of operation as follows:

\begin{itemize}
  \item 
  	\texttt{Append V} : Append a new value $V$ to the tail of array.

  \item
    \texttt{Query L R} : Query the maximum value between position $L$
and $R$. 

\end{itemize}

Now, we provide the dynamic encoding method so that each operation is
amortized $\theta(1)$ time.  First, we need to fully recognize the
formulas encoder and decoder, so that each step in the algorithm is
$\theta(1)$.

In the previous section, for any identify $\mathit{tid}$ of BST, we
can get
$\langle\mathit{lsz},\mathit{lid},\mathit{rsz},\mathit{rid}\rangle$ in
$O(n)$ time.  Oppositely, we get $\mathit{tid}$ from
$\langle\mathit{lsz},\mathit{lid},\mathit{rsz},\mathit{rid}\rangle$ in
$\theta(1)$.  The algorithm \ref{alg:encode-tid} show the inverse
function run in $\theta(1)$.  By the pre-processing, all the prefix
sum store in the memory, so the for loop can be replaced by one time
memory access in the algorithm \ref{alg:encode-tid}.

\input{algorithms/alg-encode-tid}

By the recursive formula,  we could implement without storing full
cartesian tree.  The rightmost path is consisted of the root, the
right child of the root, the right child of the right child of the
root, ..., and so on.  We maintain the rightmost path of a Cartesian
tree as a stack.  The algorithm \ref{alg :cartesian-encode-offline} is
shown for offline encoding any cartesian tree.


\input{algorithms/alg-cartesian-encode-offline}

In order to support online encoding, we use 5 variable to present the
state of the cartesian tree.  The next step will insert $i$-th
elements and final stage fill $s$ number of elements.  The current
tree label is $\mathit{tid}$ and the rightmost path of the Cartesian
tree is presented by two variable, stack pointer $\mathit{Dp}$ and the
stack $\mathit{D}$. The structure of state is as follows:

\begin{minipage}{0.9\linewidth}
\begin{lstlisting}[frame=single,caption=State of Cartesian Tree]
struct Node {
  int lsz, lid, val;
};
struct State {
  int i, s, tid, Dp;
  struct Node D[s+1];
  State(i = 0, s = n, 
          tid = C[n]-1, Dp = 0,
           D[0].val = INF)
};
\end{lstlisting}
\end{minipage}

For the online query, we choose $s=\frac{\log n}{4}$ by the Fischer's
RMQ.  In our encoding method, we initialize the $s$ number of virtual
node on the rightmost path, so the default tree label $\mathit{tid}$
is $C_s - 1$, which $C_s$ is the $s$-th Catalan number.  Following the
elements insertion, we assume the sequence of elements which is not
yet inserted are increasing.

Because of lexicographical order, the rightmost path of Cartesian tree
is belonged to the lower dimension in the row-major like.
Simultaneously, building a cartesian tree only modify the rightmost
path. We can use the propagation characteristics to get the identity
of the tree.  Finally, we design the difference algorithm
\ref{alg:cartesian- encode-online} to satisfy above requirement.

\input{algorithms/alg-cartesian-encode-online}

\begin{figure*}[!thb]
  \centering
  \includegraphics[width=\linewidth]{graphics/fig-cartesian-encoding.pdf}

  \caption{
Each block has $s$ number of elements.  We will build a cartesian tree
with $s$ number of nodes to solve in-block query.  In initialization,
it assume $s$ number of nodes on the rightmost path and the default
tree label $\mathit{tid} = C_s - 1$.  When inserting $i$-th element,
the tree label is $\mathit{tid}_i$, and the tree label of the subtree
$A$ is $A.\mathit{tid}$.  If the value of $(i+1)$-th element is $x$,
it will rotate onto the node $A$.  After rotation, $A$ is a left
subtree of $A$, and we can compute the identify of subtree $A$ during
rotation.  Then, $x.\mathit{tid}$ can be computed by the $s-(i+1)$
number of virtual nodes on the rightmost path and $A.\mathit{tid}$.
According to the lexicographical order, we get $\mathit{tid}_{i+1} =
\mathit{tid}_i + (x.\mathit{tid} - A.\mathit{tid})$.
}

  \label{fig:cartesianEncoding}
\end{figure*}

Finally, we do not increase the time complexity of the building
cartesian tree algorithm because each operation is $O(1)$.  For the
in-block query, we get the identity of the cartesian tree in $O(1)$,
and look up table to find the result.




