\section{Implementation}
\label{sec:Implementation}

\subsection{The Strategy of Disjoint Set}

There two methods to merge disjoint sets -- {\em path compression}, and
{\em rank strategy}.  Patwary, Blair, and
Manne~\cite{Patwary2010ExperimentsOU} conducted experiments on disjoint-
set, and showed that different implementations have different impact on
different levels of caches miss, such as the lower time complexity will
need the less long jumps opposite to higher time complexity use more
short jumps. % like what???

% what is the full name for RemSP? What does it mean???

The Rem's algorithm ({\sc Rem})~\cite{dijkstra1976a} is the {\sc Int}
algorithm which assumes that each node has a unique identifier that can
be ordered.  The identifier often used to express $0$ to $n$.  When
union two disjoint- set trees, we make the lower index of the root node
point to higher index of the root node. Another compression technique is
known as {\sc Splicing} ({\sc Sp}) which makes the index of new parent
of each node is higher than the index of old parent after {\sc Union}
operations.

The {\sc RemSp} is the strategy which integrates {\sc Rem} and {\sc Sp}
techniques.  The time complexity of the {\sc RemSp} is $O(m \log_{2+m/n}
n)$.  The report of Patwary et al.~\cite{Patwary2010ExperimentsOU} shows
that {\sc RemSp} is given both fewer cache missed and fewer parent jumps
than the other classical algorithms.

Recalled VGLCS problem, we consider above cache issue to implement our
program carefully.  We maintain the stack which stores the indices of
maximum value node for the {\em incremental suffix maximum query}
problem to reduce the amount of parent jumps~\cite{Peng2011TheLC} on {\sc
Append} operation.  Then, the all operations is supported by {\sc Rem}
technique.

\iffalse
運行 VGLCS 時，將耗費 $\theta(n^2)$ 的內存空間。使用遞增後綴最大值 (ISMQ) 時，
採用並查集實作將會遭遇到很多不平衡的工作負載，其原因在於合併的策略，
常見的有路徑壓縮和啟發式合併兩種策略，這間接影響到不同次數的分枝判斷。
實務上須考慮到快取未中
\fi

In the serial algorithm, we tend to actual append the new elements until
appearing the non-zero elements which is the lowest value of the integer
type in our application.  It causes less jumps and modification of the
parent for each node to improve the performance.

% what is lazy propagation???

% Due to the tendency of the dynamic programming, there are two cases in
% which the trend of the inserted value. The first case is the
% continuous zero value insert because it violates the definition.

% The second case is the insertion of incremental elements.  Finally, we
% can use the lazy propagation to improve the performance in
% implementation.

For the multi-core platform, the efficiency of thread synchronization is
the important part of the performance, so we tends to make the worst
case as more smaller as possible.  Therefore, we always merge the nodes
as possible opposite to serial algorithm.

% I cannot even undertsand this, even it is in Chinese

\iffalse
每個執行緒負責數個完整的并查集，操作時應偏向延遲標記操作，
儘早合併的策略易造成快取未中。由於動態規劃的傾向中，插入值的趨勢有兩種情況，
其一為連續不合定義的零元素插入，其二為遞增元素的插入，在這兩者穿插的趨勢中，
我們發現延遲操作將會帶來較能改善快取未中問題。
\fi

\subsection{Parallel Range Query}

%???

In the VGLCS problem, the information of range query can be reused a
lots of times.  We can reduce the amount of computation for our dynamic
programming problem by remove duplicate computation and imposing a
boundary limitation.  For example, the logarithm function is often used
in the query of a sparse table, and we can preprocessing all the result
of the requirements.  Therefore, the reduce-boundary algorithm~\ref{alg
:reduce-boundary} runs $O(n \log n)$ time, which $n$  is the length of
the input sequence.  It would not increase the time complexity because
the VGLCS problem is solved in  $O(n^2 / p + n \log n)$, which $p$ is
the number of the processors.


\iffalse
運行區間查找時，一般依賴內建函數在 $O(1)$ 時間完成對數取整，
然而，在 VGLCS 這類型的動態規劃中，區間查找的對數結果是可以被預測的，預先將每一組詢問的區段對數結果儲存在陣列中，便可降低指令次數。
\fi

\iffalse
由於已知所有詢問區間，建立稀疏表時，可藉由動態規劃在 $O(n \log n)$ 排除掉不可能的計算 (參照算法 ~\ref{alg:reduce-boundary})，
降低過程中的計算量。由於 VGLCS 在平行操作需要 $O(n \log n)$，故使用動態規劃不影響我們的最終結果。
\fi

\input{\AlgoPath/alg-reduce-boundary-2e}

Due to small $s = \frac{\log n}{4}$, the in-block query is a very
small probability event.  We can use prefix and suffix maximum array
to instead of the lookup table.  In our application, we even predict
whether the Cartesian tree is necessary to use for the in-block query.
If not, we can reduce time to compute it.  These two arrays brought
$O(n)$ space, but improve the performance by strength reduction.

\iffalse
從機率分佈的角度來看，因 $s = \frac{1}{4} \log n$ 過小，區間詢問完全落於 block 的機率低，
故額外維護區段前綴和後綴最大值 (prefix/suffix maximum value in block) 取代笛卡爾樹的建立。
藉這兩個額外儲存空間，將會增加空間複雜度的常數，卻能有效地降低整體的指令次數。
\fi
