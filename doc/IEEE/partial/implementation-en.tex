\section{Implementation}
\label{sec:Implementation}

\subsection{The Strategy of Disjoint Set}

The merging of disjoint set has two main strategies, path compression,
and rank strategy.  Patwary, Blair, and
Manne~\cite{Patwary2010ExperimentsOU} make the experiments for the
disjoint-set data structure, which impact of implementation will
encounter different level of cache miss. The {\textrm RemSP} strategy
tends to fewer cache misses and fewer parent jumps.  Therefore, we
consider above situations to implement our application carefully.

\iffalse
運行 VGLCS 時，將耗費 $\theta(n^2)$ 的內存空間。使用遞增後綴最大值 (ISMQ) 時，
採用並查集實作將會遭遇到很多不平衡的工作負載，其原因在於合併的策略，
常見的有路徑壓縮和啟發式合併兩種策略，這間接影響到不同次數的分枝判斷。
實務上須考慮到快取未中
\fi

In the serial algorithm, we tend to use lazy propagation because of the
cache miss.  Due to the tendency of the dynamic programming, there are
two cases in which the trend of the inserted value.  The first case is
the continuous zero value insert because it violates the definition.
The second case is the insertion of incremental elements.  Finally, we
can use the lazy propagation to improve the performance in
implementation.

For the multi-core platform, the efficiency of thread synchronization is
the important part of the performance, so we tends to make the worst
case as more smaller as possible.  Therefore, we always merge the groups
as possible.

\iffalse
每個執行緒負責數個完整的并查集，操作時應偏向延遲標記操作，
儘早合併的策略易造成快取未中。由於動態規劃的傾向中，插入值的趨勢有兩種情況，
其一為連續不合定義的零元素插入，其二為遞增元素的插入，在這兩者穿插的趨勢中，
我們發現延遲操作將會帶來較能改善快取未中問題。
\fi

\subsection{Parallel Range Query}

We can reduce the amount of computation for our dynamic programming
problem by remove duplicate computation and imposing a boundary
limitation.  For example, the logarithm function is often used in the
query of a sparse table, and we can preprocessing all the result of the
requirements.  In the VGLCS problem, the information of range query is
known for using.  Therefore, the reduce-boundary 
algorithm~\ref{alg:recude-boundary} runs $O(n \log n)$ time, which $n$ 
is the length of the input sequence.  It would not increase the time 
complexity because the VGLCS problem is solved in 
$O(n^2 / p + n \log n)$, which $p$ is the number of the processors.


\iffalse
運行區間查找時，一般依賴內建函數在 $O(1)$ 時間完成對數取整，
然而，在 VGLCS 這類型的動態規劃中，區間查找的對數結果是可以被預測的，預先將每一組詢問的區段對數結果儲存在陣列中，便可降低指令次數。
\fi

\iffalse
由於已知所有詢問區間，建立稀疏表時，可藉由動態規劃在 $O(n \log n)$ 排除掉不可能的計算 (參照算法 ~\ref{alg:reduce-boundary})，
降低過程中的計算量。由於 VGLCS 在平行操作需要 $O(n \log n)$，故使用動態規劃不影響我們的最終結果。
\fi

\input{\AlgoPath/alg-reduce-boundary-2e}

Due to small $s = \frac{\log n}{4}$, the in-block query is a very
small probability event.  We can use prefix and suffix maximum array
to instead of the lookup table.  In our application, we even predict
whether the Cartesian tree is necessary to use for the in-block query.
If not, we can reduce time to compute it.  These two arrays brought
$O(n)$ space, but improve the performance by strength reduction.

\iffalse
從機率分佈的角度來看，因 $s = \frac{1}{4} \log n$ 過小，區間詢問完全落於 block 的機率低，
故額外維護區段前綴和後綴最大值 (prefix/suffix maximum value in block) 取代笛卡爾樹的建立。
藉這兩個額外儲存空間，將會增加空間複雜度的常數，卻能有效地降低整體的指令次數。
\fi
