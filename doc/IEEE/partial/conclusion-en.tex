\section{Conclusion}
\label{sec:Conclusion}

In this paper, we propose a two-stages row-by-row parallel VGLCS
algorithm and optimization for both stages.  The proposed two-stage
algorithm is much more efficient than the traditional wavefront method
since it is much regular and much easy to parallelize.

%% it shrinks the length of the
%% critical path of intuitive parallel algorithm.

We use {\em sparse table} to solve the variable gapped longest common
subsequence problem.  The sparse table implementation runs efficiently
in parallel because it improves the thread synchronize and workload
imbalance than the disjoint set.  In particular, we present a
rightmost-pops encoding that is both easy-to-implement and efficient
in a parallel environment.  Our VGLCS algorithm using right-most-pops
encoding sparse table runs in $O(n^2 s / p + n \; \max(\log n, s))$,
where $n$ is the number of data, $p$ is the number of processors, and
$s$ is the block size.

We also present a tree labeling technique that order trees
lexicographically so that we can encode every binary search tree into
a Catalan index.  Then, we apply this technique in building Cartesian
tree building so that the insertion takes amortized $O(1)$ time.  As a
result the VGLCS problem can be solved in $O(n^2 / p + n \log n)$
time with this labeling technique.

Finally, we present a dynamic Catalan index computation algorithm for
sparse table.  We can answer the incremental ranged maximum query run in
amortized $O(1)$ by our sparse table, and it can be applied to the
incremental suffix maximum query as well.  The time complexity of our
VGLCS algorithm is $O(n^2 / p + n \log n)$.  Note that this dynamic
Catalan index computation technique is very general and can be applied
to other circumstances where data is constantly inserted into a binary
tree.

We observed two interesting results from our experiments.  First
blocked sparse table outperforms unblocked sparse tables in a
parallel environment.  When the block size is properly chosen, the
performance of blocked version runs more efficiently than the unblocked
version.  Second, a asymptotically better algorithm may not perform
better in practice.  For example, from our experiments we conclude
that blocked sparse table with rightmost-pops, which has a query time
$O(s)$, actually performs better than a sparse table with $O(1)$
amortized query time.  We believe that an easy and straightforward
implementation is the key of good performance, especially in a
parallel environment.
