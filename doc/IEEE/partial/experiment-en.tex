\section{Experiment} \label{sec:Experiment}

We conduct experiments on an Intel Xeon E5-2620 2.4 Ghz processor with
384K bytes of level 1 cache, 1536K bytes of level 2 cache, and 15M
bytes of shared level 3 cache.  The Intel CPU supports
hyper-threading, and each processor has six cores.  The operating
system is Ubuntu 14.04.  We implemented all algorithms in C++ and
OpenMP and compiled them using gcc with {\tt -O2} and {\tt -fopenmp}
flag.

We conduct three sets of experiments.  The first set evaluates various
data structures for supporting different queries of VGLCS problem.
The second set purely evaluates the performance of incremental suffix
maximum query using various data structures.  The third set evaluates
the performance of parallel range query.

\subsection{Variable Gapped Longest Common Subsequence}

We implement {\em disjoint set} and {\em sparse table} in our
experiments and evaluate their performance on VGLCS.  For disjoint set
we implemented path compression and rank strategies so that the
amortized time $o(\alpha(n))$.  Its variant, {\em incremental tree set
  union}~\cite{Gabow1983ALA}, has an amortized time $O(1)$ for each
query.  The sparse table has insertion time $O(\log n)$, and query
time $O(1)$.  The table is allocated in row-major to reduce cache
miss.  Please refer to Algorithm~\ref{alg:parallel-VGLCS} and
Figure~\ref{fig:interval-decomposition} for details.

We implemented four combinations of data structures in solving the
VGLCS problem and evaluated their performance.  The first combination
is a {\em sequential} implementation of Peng's algorithm using
disjoint set on {\em both} the first stage and second stage.  The
other three combinations are implemented in parallel environment.  The
{\em parallel-ST-disjoint} combination uses disjoint set in the first
stage and sparse table in the second stage.  The {\em
  parallel-COST-disjoint} combination uses disjoint set in the first
stage and compressed sparse table in the second stage.  Finally the
{\em parallel-COST} combination uses compressed sparse table in both
first and second stage.

We compare the performance of the four combinations on input strings
generated {\em randomly} from the alphabet $\{A, T, C, G\}$.
Figure~\ref{fig:fig-parallel} shows the execution time of all
combinations under different lengths of input.  We note that the
compressed sparse table implementation outperforms the theoretically
better amortized $O(1)$ sparse table implementation.  That is, {\em
parallel-COST} outperforms all other parallel implementations.  We
believe that there are two reasons for the theoretically better $O(1)$
sparse table implementation actually runs slower.  First, the encoding
Cartesian tree needs more instruction cycles to complete.

% not clear

Second, the block size is limited by the theorem.  If the block size is
large, we need a large lookup table, and then have low usage of this.
Lower usage implies that the probability of contiguous memory access is
small because of distributed storage, which would bright more cache
miss. Oppositely, if the block size is small, the theoretical time
complexity increases when we build sparse table.

Figure~\ref{fig:fig-parallel-scala} shows the scalability of the best
parallel combination {\em parallel-COST}.  It is {\em eight} times
faster than a serial implementation on our server with 6 cores and
hyper-threading.

\begin{figure}
  \centering
  \subfigure[Runtime]{
    \includegraphics[width=0.45\linewidth]{\GraphicPath/fig-parallel-n.pdf}
    \label{fig:fig-parallel}
  }
  \subfigure[Scalability]{
    \includegraphics[width=0.45\linewidth]{\GraphicPath/fig-parallel-p.pdf}
    \label{fig:fig-parallel-scala}
  }
  \caption{The execution time and scalability results of our parallel
    implementations on an E5-2620 server with 6 cores and
    hyper-threading}
\end{figure}


\subsection{Incremental Suffix Maximum Query}

We now compare the performance of {\em four} data structures for
supporting incremental suffix maximum query only.  In addition to
disjoint set and sparse table described earlier, we also implemented
{\em compressed sparse table} and {\em amortized sparse table}.  The
compressed sparse table has an amortized insertion time $O(1)$ and
query time $O(s)$, where $s$ is the size of the block and is set to
$16$ in the experiments.  Please refer to
Section~\ref{sec:parallelRMQ} for details.  The amortized sparse table
has $O(1)$ for both amortized insertion time and the query time.  In
our implementation we set the block size $s$ to $8$, and apply other
similar optimization as in compressed sparse table.

We first tried a simple scenario in which we {\em alternate} between
appending a data and issuing a range query.  Both the length and the
position of the range query are uniformly distributed among all
possibilities.  Figure~\ref{fig:fig-ISMQcmp} shows the performance of
the four data structures for supporting incremental suffix maximum
queries under this simple scenario.  We note that our compressed
sparse table implementation runs faster than the disjoint set
implementation when the number of data $n$ reaches $10^6$.  In
particular when $n$ is greater than $10^7$, the compressed sparse
table runs $1.8$ times faster than the disjoint set.

\begin{figure}[!thb]
  \centering
  \includegraphics[width=0.45\linewidth]{\GraphicPath/fig-ISMQ.pdf}
  \caption{The performance of the different data structures for
    supporting incremental suffix maximum query on an E5-2620 server}
  \label{fig:fig-ISMQcmp}
\end{figure}

Now we conduct experiments on a more complex scenario.  For example, in
dynamic programming many factors affect the performance. These factors
include the distribution of values being inserted the maximum interval
being queried.  Here we use $p$ to denote the probability of having an
larger next element to insert, $q$ for the probability of inserting a
zero, and $L$ for the maximum interval being queried.  In addition we
the number of the queries to be ten times of the number of insertions.

Table~\ref{tlb:ISMQcmp} compares timing of compressed sparse table and
the theoretically better amortized $O(1)$ sparse table to answer
incremental suffix maximum query.  The number of data $N$ is $10^7$, and
we vary the maximum interval sizes $L$ from 4 to 16, both $p$ and $q$
from 0 to 100\%.  We observe that the sparse table runs $1.5$ times
faster than the compressed table.

% answer the questions.

% What is the effect of $p$ and $q$?

The probability $p$ effects the ``peeking'' performance.  The extreme
probability $p$ will achieve excellent ``peeking'' operations.  However,
the ``peeking'' operation depends the block size, which is different
size between amortized $O(1)$ and compressed sparse table.  The
probability $q$ effects the performance of pushed/popped operation in
the stack of Cartesian tree building algorithm.  The theoretical $O(1)$
sparse table use extra computation for the Cartesian index compare to
compressed sparse table, so high probability $q$ achieve more
predictable memory access of computation.

% What is the effect of $L$?

The maximum length $L$ of interval query effects the performance of
interval query in a compressed sparse table.   That is, the block size
$s$ is 16 in our implementation, which the maximum number of instruction
for a query.  Simultaneously, the number of instructions is exactly
equal to the number of filled elements in current block.

% You need to give a reason here.  Is this because sparse table is $O(1)$?

The computation of Cartesian index maybe can be implemented well.  In
order to hide the optimized detail in implementation, we conduct this
experiment.

\input{\TablePath/tlb-ISMQcmp.tex}

\subsection{Parallel Range Maximum Query}

We now compare the performance of {\em three} data structures for
supporting parallel range maximum query only.  Since the disjoint set
only supports suffix query so we will not consider it here.  Instead
we will consider {\em sparse table}, {\em compressed sparse table},
and an {\em optimized compressed sparse table}.  The optimized
compressed sparse table implementation preprocesses all query range
sizes, and mark only the necessary compressed blocks to build.

Table~\ref{tlb:CORMQ} compares the timing results of the three data
structures for supporting parallel range query.  We set the number of
elements $N$ to be the same as the number of range queries.  We
observe that the optimized compressed sparse table is $2.35$ times
faster than sparse table when $N$ reaches $100000$.

Make more observation on $L$ and $N$.

\input{\TablePath/tlb-CORMQ.tex}
